{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet --upgrade pip\n!pip install --quiet transformers torch scipy\n!pip install --quiet faster-whisper\n!pip install --quiet flask flask-cors\n!pip install --quiet pyngrok\n!pip install --quiet torch\n!pip install --quiet numpy\n!pip install --quiet requests\n!pip install --quiet accelerate\n!pip install --quiet optimum\n\nfrom flask import Flask, request, jsonify\nimport base64\nfrom io import BytesIO\nfrom pyngrok import ngrok\nfrom flask_cors import CORS\nimport torch\nimport scipy.io.wavfile\nimport requests\nimport warnings\nfrom faster_whisper import WhisperModel\nimport os\nimport numpy as np\nimport json\nimport logging\nfrom typing import List, Dict\nimport transformers\nwarnings.filterwarnings('ignore')\ntransformers.logging.set_verbosity_error()\n\nimport uuid\nimport time\nimport sys\nimport json\nfrom pprint import pformat\n\n# Configure logging for Angelo's reel generation\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s [%(levelname)s] %(message)s',\n    handlers=[\n        logging.FileHandler(\"whisper_reel_transcription.log\"),\n        logging.StreamHandler(sys.stdout)\n    ]\n)\nlogger = logging.getLogger(__name__)\n\nprint(\"ðŸŽ¤ Initializing Whisper service for Angelo's Reel Generator...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Initialize Whisper model for Italian transcription\nmodel = WhisperModel(\n    model_size_or_path=\"base\",\n    device=device,\n    compute_type=\"float16\" if device == \"cuda\" else \"int8\"\n)\nprint(\"âœ… Whisper model loaded successfully\")\n\ndef process_audio_with_whisper(wav_file_path, request_id=None):\n    \"\"\"\n    Whisper implementation optimized for Italian reel generation\n    Returns word-level and line-level timestamps for subtitle creation\n    \"\"\"\n    if request_id is None:\n        request_id = str(uuid.uuid4())[:8]\n\n    start_time = time.time()\n    print(f\"[WHISPER-{request_id}] Starting Italian audio transcription\")\n\n    try:\n        file_size = os.path.getsize(wav_file_path)\n        print(f\"[WHISPER-{request_id}] Processing audio file: {wav_file_path} ({file_size/1024:.2f} KB)\")\n    except Exception as e:\n        print(f\"[WHISPER-{request_id}] Error getting file info: {str(e)}\")\n\n    print(f\"[WHISPER-{request_id}] Using model: base on {device}\")\n\n    try:\n        if torch.cuda.is_available():\n            memory_before = torch.cuda.memory_allocated()\n            print(f\"[WHISPER-{request_id}] Initial GPU memory: {memory_before/1024**2:.2f} MB\")\n\n        # Transcribe with Italian language preference\n        print(f\"[WHISPER-{request_id}] Starting transcription with Italian language...\")\n        transcription_start = time.time()\n        segments, info = model.transcribe(\n            wav_file_path,\n            beam_size=5,\n            word_timestamps=True,\n            language=\"it\"  # Force Italian for Angelo's content\n        )\n\n        segments = list(segments)\n        transcription_time = time.time() - transcription_start\n\n        print(f\"[WHISPER-{request_id}] âœ… Transcription completed in {transcription_time:.2f}s\")\n        print(f\"[WHISPER-{request_id}] Detected language: {info.language} (probability: {info.language_probability:.4f})\")\n        print(f\"[WHISPER-{request_id}] Number of segments: {len(segments)}\")\n\n        # Process word-level results for subtitle timing\n        print(f\"[WHISPER-{request_id}] Processing word-level timestamps for subtitles...\")\n        word_level_results = []\n        total_words = 0\n\n        for segment_idx, segment in enumerate(segments):\n            segment_words = list(segment.words)\n            total_words += len(segment_words)\n\n            print(f\"[WHISPER-{request_id}] Segment {segment_idx+1}: {len(segment_words)} words, {segment.start:.2f}s to {segment.end:.2f}s\")\n            print(f\"[WHISPER-{request_id}] Text: \\\"{segment.text}\\\"\")\n\n            for word in segment_words:\n                word_level_results.append({\n                    \"word\": word.word.strip(),\n                    \"start\": round(word.start, 2),\n                    \"end\": round(word.end, 2)\n                })\n\n        print(f\"[WHISPER-{request_id}] Total words detected: {total_words}\")\n\n        # Create line-level grouping optimized for TikTok/Reels (shorter lines)\n        print(f\"[WHISPER-{request_id}] Creating subtitle lines for mobile viewing...\")\n        line_level_results = []\n        current_line = []\n        current_text = []\n\n        # Optimized for mobile/vertical video viewing\n        MAX_CHARS = 25  # Shorter for mobile screens\n        MAX_DURATION = 2.5  # Good for TikTok pacing\n        MAX_GAP = 1.5\n\n        print(f\"[WHISPER-{request_id}] Line parameters: MAX_CHARS={MAX_CHARS}, MAX_DURATION={MAX_DURATION}s, MAX_GAP={MAX_GAP}s\")\n\n        for idx, word in enumerate(word_level_results):\n            current_line.append(word)\n            current_text.append(word[\"word\"])\n\n            line_text = \" \".join(current_text)\n            line_duration = word[\"end\"] - current_line[0][\"start\"]\n\n            should_break = False\n\n            if len(line_text) > MAX_CHARS:\n                should_break = True\n            elif line_duration > MAX_DURATION:\n                should_break = True\n            elif idx > 0:\n                gap = word[\"start\"] - word_level_results[idx-1][\"end\"]\n                if gap > MAX_GAP:\n                    should_break = True\n\n            if should_break or idx == len(word_level_results) - 1:\n                if current_line:\n                    new_line = {\n                        \"text\": \" \".join(current_text),\n                        \"start\": current_line[0][\"start\"],\n                        \"end\": current_line[-1][\"end\"],\n                        \"words\": current_line.copy()\n                    }\n                    line_level_results.append(new_line)\n                    current_line = []\n                    current_text = []\n\n        print(f\"[WHISPER-{request_id}] Created {len(line_level_results)} subtitle lines\")\n\n        # Show sample lines for verification\n        if line_level_results:\n            sample_lines = min(3, len(line_level_results))\n            print(f\"[WHISPER-{request_id}] Sample subtitle lines:\")\n            for i in range(sample_lines):\n                print(f\"  Line {i+1}: \\\"{line_level_results[i]['text']}\\\"\")\n\n        # Prepare results for reel generation\n        results = {\n            \"word_level\": word_level_results,\n            \"line_level\": line_level_results,\n            \"detected_language\": info.language,\n            \"language_probability\": info.language_probability,\n            \"processing_time\": {\n                \"transcription\": transcription_time,\n                \"total\": time.time() - start_time\n            }\n        }\n\n        if torch.cuda.is_available():\n            memory_after = torch.cuda.memory_allocated()\n            print(f\"[WHISPER-{request_id}] GPU memory after: {memory_after/1024**2:.2f} MB\")\n\n        print(f\"[WHISPER-{request_id}] âœ“ Ready for reel generation!\")\n        return results\n\n    except Exception as e:\n        print(f\"[WHISPER-{request_id}] âŒ ERROR: {str(e)}\")\n        raise\n\n    finally:\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        print(\"-\" * 50)\n\n# Flask app for ngrok exposure\napp = Flask(__name__)\nCORS(app)\n\n@app.route('/process_audio', methods=[\"POST\"])\ndef process_audio():\n    \"\"\"Process audio for Angelo's reel generation pipeline\"\"\"\n    request_id = str(uuid.uuid4())[:8]\n    start_time = time.time()\n\n    print(f\"[REEL-WHISPER-{request_id}] Received audio processing request\")\n\n    data = request.json\n    if 'audio_data' not in data:\n        print(f\"[REEL-WHISPER-{request_id}] ERROR: No audio data in request\")\n        return jsonify({\"error\": \"No audio data provided\"}), 400\n\n    audio_base64 = data['audio_data']\n    print(f\"[REEL-WHISPER-{request_id}] Audio data size: {len(audio_base64)/1024:.2f} KB\")\n\n    temp_path = f\"temp_reel_audio_{request_id}.wav\"\n    print(f\"[REEL-WHISPER-{request_id}] Saving to: {temp_path}\")\n\n    try:\n        # Decode and save audio\n        audio_bytes = base64.b64decode(audio_base64)\n        with open(temp_path, \"wb\") as f:\n            f.write(audio_bytes)\n\n        file_size = os.path.getsize(temp_path)\n        print(f\"[REEL-WHISPER-{request_id}] File created: {file_size/1024:.2f} KB\")\n\n        # Process with Whisper\n        results = process_audio_with_whisper(temp_path, request_id)\n\n        # Summary for reel generation\n        word_count = len(results[\"word_level\"])\n        line_count = len(results[\"line_level\"])\n        \n        print(f\"[REEL-WHISPER-{request_id}] Results for reel generation:\")\n        print(f\"  - Words: {word_count}\")\n        print(f\"  - Subtitle lines: {line_count}\")\n        print(f\"  - Language: {results['detected_language']}\")\n        \n        if word_count > 0:\n            audio_duration = results[\"word_level\"][-1][\"end\"]\n            print(f\"  - Duration: {audio_duration:.2f}s\")\n\n        total_time = time.time() - start_time\n        print(f\"[REEL-WHISPER-{request_id}] âœ“ Processing complete in {total_time:.2f}s\")\n\n        return jsonify(results)\n\n    except Exception as e:\n        print(f\"[REEL-WHISPER-{request_id}] âŒ ERROR: {str(e)}\")\n        return jsonify({\"error\": str(e)}), 500\n\n    finally:\n        if os.path.exists(temp_path):\n            os.remove(temp_path)\n            print(f\"[REEL-WHISPER-{request_id}] Temp file cleaned up\")\n\n# Ngrok setup for external access\ndef create_app():\n    \"\"\"Create ngrok tunnel for Angelo's reel generation service\"\"\"\n    try:\n        print(\"ðŸŒ Setting up ngrok tunnel for Whisper service...\")\n        ngrok.set_auth_token(\"\")\n        public_url = ngrok.connect(5000).public_url\n        \n        print(f\"âœ… Whisper service available at: {public_url}\")\n        print(f\"   Endpoint: {public_url}/process_audio\")\n        print(f\"   Use this URL in your WHISPER_NGROK_URL environment variable\")\n        \n        # Optional: notify Django service (if running)\n        try:\n            response = requests.post(\n                'https://c8e168cf22ff.ngrok-free.app/update-ngrok-url3/',\n                json={\"ngrok_url\": public_url}\n            )\n            logger.info(\"Ngrok URL sent to Django service\")\n        except Exception as e:\n            logger.info(f\"Django notification failed (this is optional): {e}\")\n\n        return app, public_url\n\n    except Exception as e:\n        print(f\"âŒ Ngrok setup failed: {e}\")\n        return None, None\n\n# Start the service\nprint(\"ðŸš€ Starting Whisper service for Angelo's Reel Generator...\")\nif __name__ == '__main__':\n    app, url = create_app()\n    if app:\n        print(\"ðŸŽ¤ Whisper service is ready for reel generation!\")\n        app.run(port=5000)\n    else:\n        print(\"âŒ Failed to start Whisper service\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:45:20.543729Z","iopub.execute_input":"2025-11-08T09:45:20.544289Z","execution_failed":"2025-11-08T10:18:13.362Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mðŸŽ¤ Initializing Whisper service for Angelo's Reel Generator...\nUsing device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocabulary.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4248f8cb626944eda7bd8898c7e333d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c0352a4cbe487bae127ec99efb42d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dfb16108c9b4b1c934e241c0abd612e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e396d8c646b7445a8458dd1ada8ec246"}},"metadata":{}},{"name":"stdout","text":"âœ… Whisper model loaded successfully\nðŸš€ Starting Whisper service for Angelo's Reel Generator...\nðŸŒ Setting up ngrok tunnel for Whisper service...\nâœ… Whisper service available at: https://60c266720c54.ngrok-free.app                                 \n   Endpoint: https://60c266720c54.ngrok-free.app/process_audio\n   Use this URL in your WHISPER_NGROK_URL environment variable\nðŸŽ¤ Whisper service is ready for reel generation!\n * Serving Flask app '__main__'\n * Debug mode: off\n[REEL-WHISPER-fde774fe] Received audio processing request\n[REEL-WHISPER-fde774fe] Audio data size: 930.67 KB\n[REEL-WHISPER-fde774fe] Saving to: temp_reel_audio_fde774fe.wav\n[REEL-WHISPER-fde774fe] File created: 698.00 KB\n[WHISPER-fde774fe] Starting Italian audio transcription\n[WHISPER-fde774fe] Processing audio file: temp_reel_audio_fde774fe.wav (698.00 KB)\n[WHISPER-fde774fe] Using model: base on cuda\n[WHISPER-fde774fe] Initial GPU memory: 0.00 MB\n[WHISPER-fde774fe] Starting transcription with Italian language...\n[WHISPER-fde774fe] âœ… Transcription completed in 2.40s\n[WHISPER-fde774fe] Detected language: it (probability: 1.0000)\n[WHISPER-fde774fe] Number of segments: 8\n[WHISPER-fde774fe] Processing word-level timestamps for subtitles...\n[WHISPER-fde774fe] Segment 1: 20 words, 0.00s to 5.32s\n[WHISPER-fde774fe] Text: \" Gestire tutto da solo? Ãˆ un po' come navigare in mare aperto senza busso, la prima o poi ti perdi.\"\n[WHISPER-fde774fe] Segment 2: 21 words, 5.76s to 12.32s\n[WHISPER-fde774fe] Text: \" Con Smartgain non sei mai solo. C'Ã¨ una community vera, fatta di persone reali che ti affiancano in ogni momento.\"\n[WHISPER-fde774fe] Segment 3: 14 words, 12.74s to 17.20s\n[WHISPER-fde774fe] Text: \" Persone competenti che leggono clausole e contratti insieme a te, non al posto tuo.\"\n[WHISPER-fde774fe] Segment 4: 15 words, 17.50s to 22.96s\n[WHISPER-fde774fe] Text: \" Niente col center dove nessuno ti conosce, niente risposte, pre-confezionate che non risolvono nulla.\"\n[WHISPER-fde774fe] Segment 5: 15 words, 23.38s to 27.84s\n[WHISPER-fde774fe] Text: \" Qui c'Ã¨ solo supporto vero, con persone che capiscono davvero quello che stai affrontando.\"\n[WHISPER-fde774fe] Segment 6: 14 words, 27.84s to 32.36s\n[WHISPER-fde774fe] Text: \" In pari dai casi degli altri, condividi i tuoi dubbi e prendi decisioni consapevoli.\"\n[WHISPER-fde774fe] Segment 7: 19 words, 32.80s to 41.00s\n[WHISPER-fde774fe] Text: \" Ogni singolo passo, trasparenza totale sempre, vuoi unirti alla community smartgain, trovi tutte le informazioni nel link in bio\"\n[WHISPER-fde774fe] Segment 8: 10 words, 41.00s to 44.32s\n[WHISPER-fde774fe] Text: \" oppure se commenti con Smart ti mandiamo tutti i dettagli.\"\n[WHISPER-fde774fe] Total words detected: 128\n[WHISPER-fde774fe] Creating subtitle lines for mobile viewing...\n[WHISPER-fde774fe] Line parameters: MAX_CHARS=25, MAX_DURATION=2.5s, MAX_GAP=1.5s\n[WHISPER-fde774fe] Created 25 subtitle lines\n[WHISPER-fde774fe] Sample subtitle lines:\n  Line 1: \"Gestire tutto da solo? Ãˆ un\"\n  Line 2: \"po' come navigare in mare aperto\"\n  Line 3: \"senza busso, la prima o poi\"\n[WHISPER-fde774fe] GPU memory after: 0.00 MB\n[WHISPER-fde774fe] âœ“ Ready for reel generation!\n--------------------------------------------------\n[REEL-WHISPER-fde774fe] Results for reel generation:\n  - Words: 128\n  - Subtitle lines: 25\n  - Language: it\n  - Duration: 44.32s\n[REEL-WHISPER-fde774fe] âœ“ Processing complete in 3.20s\n[REEL-WHISPER-fde774fe] Temp file cleaned up\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}